[
  {
    "model_path": "/models/ggml-model-7b_m-q6_k.gguf",
    "model_name": "Llama2",
    "model_type": "LLAMA2",
    "context_size": 512,
    "main_gpu": null,
    "gpu_layers": 0,
    "split_mode": 1,
    "seed": -1,
    "logits_all": false,
    "vocab_only": false,
    "mmap": true,
    "mlock": false,
    "embedding": false,
    "threads": 4,
    "threads_batch": 4,
    "batch_size": 512,
    "last_tokens_size": 64,
    "lora_base": null,
    "lora_path": null,
    "lora_scale": 0.0,
    "tensor_split": null,
    "rope_freq_base": 0.0,
    "rope_freq_scale": 0.0,
    "gqa": null,
    "rms_norm_eps": null,
    "mul_mat_q": true,
    "verbose": false,
    "rope_scaling_type": -1,
    "yarn_ext_factor": -1.0,
    "yarn_attn_factor": 1.0,
    "yarn_beta_fast": 32.0,
    "yarn_beta_slow": 1.0,
    "yarn_orig_ctx": 0,
    "offload_kqv": true
  }
]