# â˜•ï¸ Java bindings for [`llama.cpp`](https://github.com/ggerganov/llama.cpp)


[![README Zh_CN](https://img.shields.io/badge/Lang-ä¸­æ–‡-red)](./README.Zh_CN.md)
[![README English](https://img.shields.io/badge/Lang-English-blue)](./README.md)
[![Llama java chat](https://img.shields.io/badge/Github-llama_java_chat-green)](https://github.com/eoctet/llama-java-chat.git)
![GitHub all releases](https://img.shields.io/github/downloads/eoctet/llama-java-core/total)
![GitHub language count](https://img.shields.io/github/languages/count/eoctet/llama-java-core)
[![GitHub](https://img.shields.io/github/license/eoctet/llama-java-core)](https://opensource.org/licenses/MIT)


è¿™æ˜¯ä¸€ä¸ªåŸºäº ğŸ¦™[`llama.cpp`](https://github.com/ggerganov/llama.cpp)  APIå¼€å‘çš„Javaåº“ï¼Œç›®æ ‡æ˜¯æ›´å¿«é€Ÿå°†å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›é›†æˆåˆ°Javaç”Ÿæ€ï¼Œæœ¬é¡¹ç›®å’Œå…¶ä»–è¯­è¨€ç‰ˆæœ¬åº“å…·æœ‰ä¸€æ ·çš„åŠŸèƒ½ã€‚

#### ä¸»è¦ç‰¹ç‚¹
- ğŸš€ åŸºäº Llama.cpp æ„å»ºï¼Œæ›´å¤šç»†èŠ‚è¯·å…³æ³¨ **@ggerganov's** [`llama.cpp`](https://github.com/ggerganov/llama.cpp)ã€‚
- ğŸš€ ä½¿ç”¨JNIå¼€å‘æœ¬åœ°åº“ï¼Œ~~è€Œä¸æ˜¯JNA~~ï¼Œæµ‹è¯•çš„æ€§èƒ½ä¸Šä¸å…¶ä»–åº“æ— å¼‚ã€‚
- ğŸš€ æ–°å¢:
  - [X] è¿ç»­ç”Ÿæˆå’Œå¯¹è¯ã€‚
  - [X] Llama è¯­æ³•è§£æã€‚
  - [X] å¹¶è¡Œæ‰¹å¤„ç†è§£ç ã€‚

## å¿«é€Ÿå¼€å§‹

#### Maven POM

```xml
<dependency>
    <groupId>chat.octet</groupId>
    <artifactId>llama-java-core</artifactId>
    <version>1.1.6</version>
</dependency>
```

#### Examples

- **Chat Console Example**

è¿™é‡Œæä¾›äº†ä¸€ä¸ªç®€å•çš„èŠå¤©ç¤ºä¾‹ï¼Œä½ ä¹Ÿå¯ä»¥å‚è€ƒ ğŸ¤–ï¸ [**Llama-Java-Chat**](https://github.com/eoctet/llama-java-chat.git) è¿›ä¸€æ­¥ä¸°å¯Œä½ çš„åº”ç”¨ã€‚

```java
public class ConsoleExample {
    private static final String MODEL_PATH = "/llama.cpp/models/llama2/ggml-model-7b-q6_k.gguf";

    public static void main(String[] args) {
        ModelParameter modelParams = ModelParameter.builder()
                .modelPath(MODEL_PATH)
                .threads(6)
                .contextSize(4096)
                .verbose(true)
                .build();

        try (BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));
             Model model = new Model(modelParams)) {

            GenerateParameter generateParams = GenerateParameter.builder().build();
            String system = "Answer the questions.";

            while (true) {
                System.out.print("\nQuestion: ");
                String input = bufferedReader.readLine();
                if (StringUtils.trimToEmpty(input).equalsIgnoreCase("exit")) {
                    break;
                }
                model.chat(generateParams, system, input).forEach(e -> System.out.print(e.getText()));
                System.out.print("\n");
                model.metrics();
            }
        } catch (Exception e) {
            System.err.println("Error: " + e);
            System.exit(1);
        }
    }
}
```

- **Continuous Chat Example**

```java
public class ContinuousChatExample {

    private static final String MODEL_PATH = "/llama.cpp/models/llama2/ggml-model-7b-q6_k.gguf";

    public static void main(String[] args) {
        String system = "You are a helpful assistant. ";
        String[] questions = new String[]{
                "List five emojis about food and explain their meanings",
                "Write a fun story based on the third emoji",
                "Continue this story and refine it",
                "Summarize a title for this story, extract five keywords, and the keywords should not exceed five words",
                "Mark the characters, time, and location of this story",
                "Great, translate this story into Chinese",
                "Who are you and why are you here?",
                "Summarize today's conversation"
        };

        GenerateParameter generateParams = GenerateParameter.builder()
                .verbosePrompt(true)
                .user("William")
                .build();

        try (Model model = new Model(MODEL_PATH)) {
            for (String question : questions) {
                //Example 1: Continuous generation example.
                //String text = PromptBuilder.toPrompt(system, question);
                //model.generate(generateParams, text).forEach(e -> System.out.print(e.getText()));

                //Example 2: Continuous chat example
                model.chat(generateParams, system, question).forEach(e -> System.out.print(e.getText()));
                System.out.println("\n");
                model.metrics();
            }
        }
    }
}
```

> More examples: [chat.octet.test](src%2Ftest%2Fjava%2Fchat%2Foctet%2Ftest)


## å¼€å‘æ‰‹å†Œ

#### è‡ªå®šä¹‰æ¨ç†

- **Components**
  - LogitsProcessor
  - StoppingCriteria

å¯ä»¥ä½¿ç”¨ `LogitsProcessor` å’Œ `StoppingCriteria` å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹è¿›è¡Œè‡ªå®šä¹‰æ§åˆ¶ã€‚

> æ³¨ï¼šå¦‚æœéœ€è¦åœ¨Javaä¸­è¿›è¡ŒçŸ©é˜µè®¡ç®—è¯·ä½¿ç”¨ [`openblas`](https://github.com/bytedeco/javacpp-presets/tree/master/openblas)

**chat.octet.model.components.processor.LogitsProcessor**

è‡ªå®šä¹‰ä¸€ä¸ªå¤„ç†å™¨å¯¹è¯çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œæ§åˆ¶æ¨¡å‹æ¨ç†çš„ç”Ÿæˆç»“æœã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š[NoBadWordsLogitsProcessor.java](src%2Fmain%2Fjava%2Fchat%2Foctet%2Fmodel%2Fcomponents%2Fprocessor%2Fimpl%2FNoBadWordsLogitsProcessor.java)

```java
Map<Integer, String> logitBias = Maps.newLinkedHashMap();
logitBias.put(5546, "false");
logitBias.put(12113, "5.89");
LogitsProcessorList logitsProcessorList = new LogitsProcessorList(Lists.newArrayList(new CustomBiasLogitsProcessor(logitBias, model.getVocabSize())));

GenerateParameter generateParams = GenerateParameter.builder()
        .logitsProcessorList(logitsProcessorList)
        .build();

...

```

**chat.octet.model.components.criteria.StoppingCriteria**

è‡ªå®šä¹‰ä¸€ä¸ªæ§åˆ¶å™¨å®ç°å¯¹æ¨¡å‹æ¨ç†çš„åœæ­¢è§„åˆ™æ§åˆ¶ï¼Œä¾‹å¦‚ï¼šæ§åˆ¶ç”Ÿæˆæœ€å¤§è¶…æ—¶æ—¶é—´ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š[MaxTimeCriteria](src%2Fmain%2Fjava%2Fchat%2Foctet%2Fmodel%2Fcomponents%2Fcriteria%2Fimpl%2FMaxTimeCriteria.java)

```java
long maxTime = TimeUnit.MINUTES.toMillis(Optional.ofNullable(params.getTimeout()).orElse(10L));
StoppingCriteriaList stopCriteriaList = new StoppingCriteriaList(Lists.newArrayList(new MaxTimeCriteria(maxTime)));

GenerateParameter generateParams = GenerateParameter.builder()
        .stoppingCriteriaList(stopCriteriaList)
        .build();

...

```

#### [LlamaService](src%2Fmain%2Fjava%2Fchat%2Foctet%2Fmodel%2FLlamaService.java)

ä½¿ç”¨JNIå¼€å‘ï¼Œå¼€æ”¾ä¸åŸé¡¹ç›®ç›¸åŒçš„æ¥å£å¹¶ä¼˜åŒ–JVM Nativeæ€§èƒ½ã€‚

> `LlamaService` å¯¹APIè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥å‡å°‘JVM Nativeä¹‹é—´æ•°æ®ä¼ é€’å¸¦æ¥çš„æ€§èƒ½æŸå¤±ã€‚
>
>
> å®Œæ•´çš„æ–‡æ¡£è¯·å‚è€ƒ [API docs](docs%2Fapidocs%2Findex.html)ã€‚

#### å¦‚ä½•ç¼–è¯‘

é»˜è®¤å·²åŒ…å«å„ç³»ç»Ÿç‰ˆæœ¬åº“ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

> å¦‚æœéœ€è¦æ”¯æŒ`GPU`æˆ–æ›´åŠ çµæ´»çš„ç¼–è¯‘æ–¹å¼ï¼Œè¯·å‚è€ƒ `llama.cpp` **Build** æ–‡æ¡£ã€‚

```ini
# åŠ è½½å¤–éƒ¨åº“æ–‡ä»¶

-Doctet.llama.lib=<YOUR_LIB_PATH>
```

## Why Java

æ²¡æœ‰ç‰¹æ®Šç†ç”±ï¼Œæˆ‘å¸Œæœ›è¿™ä¸æ˜¯ç²—ç‡¥çš„APIå°è£…ï¼Œåœ¨æ­¤åŸºç¡€ä¹‹ä¸Šåšä¸€äº›ä¼˜åŒ–å’Œæ‰©å±•ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç§»æ¤åˆ°Javaç”Ÿæ€ã€‚


## é—®é¢˜åé¦ˆ

- å¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®ï¼Œæ¬¢è¿åœ¨GitHub Issueä¸­æäº¤ã€‚


