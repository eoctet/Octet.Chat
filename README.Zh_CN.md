# ğŸ¦™ LLaMA Java â˜•ï¸


[![CI](https://github.com/eoctet/llama-java-core/actions/workflows/maven_build_deploy.yml/badge.svg)](https://github.com/eoctet/llama-java-core/actions/workflows/maven_build_deploy.yml)
[![Maven Central](https://img.shields.io/maven-central/v/chat.octet/llama-java-core?color=orange)](https://mvnrepository.com/artifact/chat.octet/llama-java-core)
[![README English](https://img.shields.io/badge/Lang-English-red)](./README.md)
[![GitHub](https://img.shields.io/github/license/eoctet/llama-java-core?color=green)](https://opensource.org/licenses/MIT)

è¿™ä¸ªæ˜¯ä¸€ä¸ª ğŸ¦™ `LLaMA Java` å®ç°ã€‚æä¾›äº†ä¸€ä¸ªJavaåº“ `llama-java-core` ä»¥åŠä¸€ä¸ªå®Œæ•´çš„APIæœåŠ¡ï¼Œä½ å¯ä»¥ç”¨å®ƒéƒ¨ç½²è‡ªå·±çš„ç§æœ‰æœåŠ¡ï¼Œæ”¯æŒ `Llama2` ç³»åˆ—æ¨¡å‹åŠå…¶ä»–å¼€æºæ¨¡å‹ã€‚

#### ä¸»è¦ç‰¹ç‚¹
- ğŸ¦™ åŸºäº  [`llama.cpp`](https://github.com/ggerganov/llama.cpp) æ„å»º
- ğŸš€ æ”¯æŒ `OpenAPI`ï¼Œå¿«é€Ÿå®ç°ç§æœ‰åŒ–æœåŠ¡
- ğŸ¤– æ”¯æŒ `å¹¶è¡Œæ¨ç†`ã€`è¿ç»­å¯¹è¯` å’Œ `æ–‡æœ¬ç”Ÿæˆ`
- ğŸ“¦ æ”¯æŒ `Llama2` ç³»åˆ—æ¨¡å‹å’Œå…¶ä»–å¼€æºæ¨¡å‹ï¼Œä¾‹å¦‚ï¼š`Baichuan 7B`ã€`QWen 7B`
- â˜•ï¸ ä½¿ç”¨ `JNI` å¼€å‘æœ¬åœ°åº“ï¼Œæä¾›ä¸ `Llama.cpp` ä¸€è‡´çš„æ¥å£
- ğŸ’» æ”¯æŒ `å‘½ä»¤è¡Œäº¤äº’` å’Œ `æœåŠ¡ç«¯éƒ¨ç½²`

#### æœ€è¿‘æ›´æ–°
- [X] ğŸš€ æä¾›æ¨¡å‹é‡åŒ–æ¥å£
- [X] ğŸš€ è‡ªå®šä¹‰æ¨¡å‹çš„æç¤ºè¯æ¨¡ç‰ˆï¼ˆä¾‹å¦‚ï¼šVicunaã€Alpacaç­‰ç­‰ï¼‰
- [X] ğŸš€ å¹¶è¡Œæ‰¹å¤„ç†è§£ç 
- [X] ğŸš€ Min-P é‡‡æ ·æ”¯æŒ
- [X] ğŸš€ YaRN RoPE æ”¯æŒ

## å¿«é€Ÿå¼€å§‹

#### ğŸ–¥ æœåŠ¡ç«¯éƒ¨ç½²

- ä¸‹è½½å¹¶å¯åŠ¨æœåŠ¡

```bash
# Default URL: http://YOUR_IP_ADDR:8152/

cd <YOUR_PATH>/llama-java-app
bash app_server.sh start
```

- ç›®å½•ç¤ºä¾‹

```text
=> llama-java-app
   âŒŠ___ llama-java-app.jar
   âŒŠ___ app_server.sh
   âŒŠ___ conf
        âŒŠ___ setting.json

Â·Â·Â·
```

ä¸ `ChatGPT` çš„æ¥å£è§„èŒƒä¿æŒä¸€è‡´ï¼Œä»…å®ç°ä¸»è¦çš„æ¥å£ï¼Œå¯ä»¥ä¸ [`ChatGPT Next Web`](https://github.com/Yidadaa/ChatGPT-Next-Web) ç­‰WebUIã€Appé›†æˆä½¿ç”¨ã€‚

> â„¹ï¸ __å…¶ä¸­ä¸åŒä¹‹å¤„__
> 1. æ–°å¢äº†Llamaç³»åˆ—æ¨¡å‹çš„å‚æ•°ï¼Œåˆ é™¤äº†ä¸æ”¯æŒçš„GPTå‚æ•°ï¼›
> 2. é»˜è®¤ä½¿ç”¨äº† `Llama2-chat` æç¤ºè¯æ¨¡ç‰ˆï¼Œå¦‚éœ€é€‚é…å…¶ä»–æ¨¡å‹ï¼Œå¯è‡ªè¡Œè°ƒæ•´ï¼›
> 3. æ²¡æœ‰è¯·æ±‚è®¤è¯ã€ä½¿ç”¨é‡æŸ¥è¯¢ç­‰ä¸éœ€è¦çš„åŠŸèƒ½ï¼›
> 4. ä¼˜åŒ–å¯¹è¯èŠå¤©æ¥å£ï¼Œä¸éœ€è¦ä¼ é€’å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä»…å½“å‰å¯¹è¯å†…å®¹å³å¯ã€‚
>
> > å®Œæ•´çš„APIä¿¡æ¯è¯·å‚è€ƒ[`API æ–‡æ¡£`](docs/API.md)ã€‚

![webui.png](docs%2Fwebui.png)

ä¸¾ä¸ªæ —å­

> `POST` **/v1/chat/completions**

```shell
curl --location 'http://127.0.0.1:8152/v1/chat/completions' \
--header 'Content-Type: application/json' \
--data '{
    "messages": [
        {
            "role": "SYSTEM",
            "content": "<YOUR_PROMPT>"
        },
        {
            "role": "USER",
            "content": "Who are you?"
        }
    ],
    "user": "william",
    "verbose": true,
    "stream": true,
    "model": "Llama2-chat"
}'
```

æ¥å£å°†ä»¥æµçš„æ–¹å¼è¿”å›æ•°æ®ï¼š

```json
{
    "id": "octetchat-98fhd2dvj7",
    "model": "Llama2-chat",
    "created": 1695614393810,
    "choices": [
        {
            "index": 0,
            "delta": {
                "content": "ä½ å¥½"
            },
            "finish_reason": "NONE"
        }
    ]
}
```

#### ğŸ¤– å‘½ä»¤è¡Œäº¤äº’

è¿è¡Œå‘½ä»¤è¡Œäº¤äº’ï¼ŒæŒ‡å®šéœ€è¦åŠ è½½çš„è¯­è¨€æ¨¡å‹ã€‚

```bash
java -jar llama-java-app.jar --model llama2-chat --system 'YOUR_PROMPT'
```

```txt
... ...

User: ä½ æ˜¯è°
AI: ä½œä¸ºä¸€ä¸ª AIï¼Œæˆ‘ä¸çŸ¥é“æˆ‘æ˜¯è°ã€‚æˆ‘çš„è®¾è®¡è€…å’Œåˆ›å»ºè€…åˆ›é€ äº†æˆ‘ã€‚
ä½†æ˜¯ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè™šæ‹ŸåŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›å¸®åŠ©å’Œå›ç­”é—®é¢˜ã€‚
```

> ä½¿ç”¨ `help` æŸ¥çœ‹æ›´å¤šå‚æ•°ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```bash
java -jar llama-java-app.jar --help

usage: LLAMA-JAVA-APP
    --app <arg>                 App launch type: cli | api (default: cli).
 -c,--completions               Use completions mode.
    --frequency-penalty <arg>   Repeat alpha frequency penalty (default:
                                0.0, 0.0 = disabled)
 -h,--help                      Show this help message and exit.
 -m,--model <arg>               Load model name, default: llama2-chat.
    --max-new-tokens <arg>      Maximum new token generation size
                                (default: 0 unlimited).
    --min-p <arg>               Min-p sampling (default: 0.05, 0 =
                                disabled).
    --mirostat <arg>            Enable Mirostat sampling, controlling
                                perplexity during text generation
                                (default: 0, 0 = disabled, 1 = Mirostat, 2
                                = Mirostat 2.0).
    --mirostat-ent <arg>        Set the Mirostat target entropy, parameter
                                tau (default: 5.0).
    --mirostat-lr <arg>         Set the Mirostat learning rate, parameter
                                eta (default: 0.1).
    --no-penalize-nl <arg>      Disable penalization for newline tokens
                                when applying the repeat penalty (default:
                                true).
    --presence-penalty <arg>    Repeat alpha presence penalty (default:
                                0.0, 0.0 = disabled)
    --repeat-penalty <arg>      Control the repetition of token sequences
                                in the generated text (default: 1.1).
    --system <arg>              Set a system prompt.
    --temperature <arg>         Adjust the randomness of the generated
                                text (default: 0.8).
    --tfs <arg>                 Enable tail free sampling with parameter z
                                (default: 1.0, 1.0 = disabled).
    --top-k <arg>               Top-k sampling (default: 40, 0 =
                                disabled).
    --top-p <arg>               Top-p sampling (default: 0.9).
    --typical <arg>             Enable typical sampling sampling with
                                parameter p (default: 1.0, 1.0 =
                                disabled).
    --verbose-prompt            Print the prompt before generating text.
```

## å¼€å‘æ‰‹å†Œ

#### Maven POM

```xml
<dependency>
    <groupId>chat.octet</groupId>
    <artifactId>llama-java-core</artifactId>
    <version>1.3.0</version>
</dependency>
```

#### Examples

- **Chat Console Example**

è¿™é‡Œæä¾›äº†ä¸€ä¸ªç®€å•çš„èŠå¤©ç¤ºä¾‹ã€‚

```java
public class ConsoleExample {
    private static final String MODEL_PATH = "/llama-java-app/models/llama2/ggml-model-7b-q6_k.gguf";

    public static void main(String[] args) {
        ModelParameter modelParams = ModelParameter.builder()
                .modelPath(MODEL_PATH)
                .threads(6)
                .contextSize(4096)
                .verbose(true)
                .build();

        try (BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));
             Model model = new Model(modelParams)) {

            GenerateParameter generateParams = GenerateParameter.builder().build();
            String system = "Answer the questions.";

            while (true) {
                System.out.print("\nQuestion: ");
                String input = bufferedReader.readLine();
                if (StringUtils.trimToEmpty(input).equalsIgnoreCase("exit")) {
                    break;
                }
                model.chat(generateParams, system, input).output();
                System.out.print("\n");
                model.metrics();
            }
        } catch (Exception e) {
            System.err.println("Error: " + e);
            System.exit(1);
        }
    }
}
```

- **Continuous Chat Example**

```java
public class ContinuousChatExample {

    private static final String MODEL_PATH = "/llama-java-app/models/llama2/ggml-model-7b-q6_k.gguf";

    public static void main(String[] args) {
        String system = "You are a helpful assistant. ";
        String[] questions = new String[]{
                "List five emojis about food and explain their meanings",
                "Write a fun story based on the third emoji",
                "Continue this story and refine it",
                "Summarize a title for this story, extract five keywords, and the keywords should not exceed five words",
                "Mark the characters, time, and location of this story",
                "Great, translate this story into Chinese",
                "Who are you and why are you here?",
                "Summarize today's conversation"
        };

        GenerateParameter generateParams = GenerateParameter.builder()
                .verbosePrompt(true)
                .user("William")
                .build();

        try (Model model = new Model(MODEL_PATH)) {
            for (String question : questions) {
                //Example 1: Continuous generation example.
                //String text = PromptBuilder.toPrompt(system, question);
                //model.generate(generateParams, text).output();

                //Example 2: Continuous chat example
                model.chat(generateParams, system, question).output();
                System.out.println("\n");
                model.metrics();
            }
        }
    }
}
```

> More examples: `chat.octet.examples.*`


#### Components
  - `LogitsProcessor`
  - `StoppingCriteria`

å¯ä»¥ä½¿ç”¨ `LogitsProcessor` å’Œ `StoppingCriteria` å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹è¿›è¡Œè‡ªå®šä¹‰æ§åˆ¶ã€‚

> æ³¨ï¼šå¦‚æœéœ€è¦åœ¨Javaä¸­è¿›è¡ŒçŸ©é˜µè®¡ç®—è¯·ä½¿ç”¨ [`openblas`](https://github.com/bytedeco/javacpp-presets/tree/master/openblas)

**chat.octet.model.components.processor.LogitsProcessor**

è‡ªå®šä¹‰ä¸€ä¸ªå¤„ç†å™¨å¯¹è¯çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œæ§åˆ¶æ¨¡å‹æ¨ç†çš„ç”Ÿæˆç»“æœã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š[NoBadWordsLogitsProcessor.java](src%2Fmain%2Fjava%2Fchat%2Foctet%2Fmodel%2Fcomponents%2Fprocessor%2Fimpl%2FNoBadWordsLogitsProcessor.java)

```java
    Map<Integer, String> logitBias = Maps.newLinkedHashMap();
    logitBias.put(5546, "false");
    logitBias.put(12113, "5.89");
    LogitsProcessorList logitsProcessorList = new LogitsProcessorList(Lists.newArrayList(new CustomBiasLogitsProcessor(logitBias, model.getVocabSize())));
    
    GenerateParameter generateParams = GenerateParameter.builder()
            .logitsProcessorList(logitsProcessorList)
            .build();
```

**chat.octet.model.components.criteria.StoppingCriteria**

è‡ªå®šä¹‰ä¸€ä¸ªæ§åˆ¶å™¨å®ç°å¯¹æ¨¡å‹æ¨ç†çš„åœæ­¢è§„åˆ™æ§åˆ¶ï¼Œä¾‹å¦‚ï¼šæ§åˆ¶ç”Ÿæˆæœ€å¤§è¶…æ—¶æ—¶é—´ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š[MaxTimeCriteria](src%2Fmain%2Fjava%2Fchat%2Foctet%2Fmodel%2Fcomponents%2Fcriteria%2Fimpl%2FMaxTimeCriteria.java)

```java
    long maxTime = TimeUnit.MINUTES.toMillis(Optional.ofNullable(params.getTimeout()).orElse(10L));
    StoppingCriteriaList stopCriteriaList = new StoppingCriteriaList(Lists.newArrayList(new MaxTimeCriteria(maxTime)));
    
    GenerateParameter generateParams = GenerateParameter.builder()
            .stoppingCriteriaList(stopCriteriaList)
            .build();
```

> å®Œæ•´çš„æ–‡æ¡£è¯·å‚è€ƒ [Java docs](docs%2Fapidocs%2Findex.html)

#### å¦‚ä½•ç¼–è¯‘

é»˜è®¤å·²åŒ…å«å„ç³»ç»Ÿç‰ˆæœ¬åº“ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

> å¦‚æœéœ€è¦æ›´åŠ çµæ´»çš„ç¼–è¯‘æ–¹å¼ï¼Œè¯·å‚è€ƒ `llama.cpp` **Build** æ–‡æ¡£ã€‚

```ini
# åŠ è½½å¤–éƒ¨åº“æ–‡ä»¶

-Doctet.llama.lib=<YOUR_LIB_PATH>
```

## é—®é¢˜åé¦ˆ

- å¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®ï¼Œæ¬¢è¿åœ¨GitHub Issueä¸­æäº¤ã€‚
