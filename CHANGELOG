1. Update inference generator.
2. Update llama.cpp libs version to b1395.