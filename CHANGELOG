- Add KV cache parameters
- Merge the `llama-java-chat` project
- Add model quantization support
